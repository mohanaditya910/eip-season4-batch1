{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist-Adamwithallimprovements.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohanaditya910/eip-season4-batch1/blob/master/week2/mnist_submission_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofdloK0vtKYQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "9c3f65b8-4ec9-4a3e-99ec-ce709a17565c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uC_NakgYtZMF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb30118a-13de-4f66-c9e7-e6d705e6c209"
      },
      "source": [
        "!mkdir drive/'My Drive'/models/mnist-data_augmentation"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘drive/My Drive/models/mnist-data_augmentation’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JL1kZKW0tchC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "8957956d-5dec-4f62-fceb-6c8434385cc4"
      },
      "source": [
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SE2YC6V4toP3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyJGlW4YtqJr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#########data augmentation cell#####################\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "    samplewise_center=False,  # set each sample mean to 0\n",
        "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "    samplewise_std_normalization=False,  # divide each input by its std\n",
        "    zca_whitening=False,  # apply ZCA whitening\n",
        "    zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "    rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    # randomly shift images horizontally (fraction of total width)\n",
        "    width_shift_range=0.05,\n",
        "    # randomly shift images vertically (fraction of total height)\n",
        "    height_shift_range=0.05,\n",
        "    shear_range=0.2,  # set range for random shear\n",
        "    zoom_range=0.05,  # set range for random zoom\n",
        "    channel_shift_range=0.,  # set range for random channel shifts\n",
        "    # set mode for filling points outside the input boundaries\n",
        "    fill_mode='nearest',\n",
        "    cval=0.,  # value used for fill_mode = \"constant\"\n",
        "    horizontal_flip=False,  # randomly flip images   ############not advisable because some numbers when flipped can represent other numbers..\n",
        "    vertical_flip=False,  # randomly flip images     #########################\n",
        "    # set rescaling factor (applied before any other transformation)\n",
        "    rescale=None, #already done....\n",
        "    # set function that will be applied on each input\n",
        "    preprocessing_function=None,\n",
        "\n",
        "##############can explore this part......\n",
        "\n",
        "\n",
        "    # image data format, either \"channels_first\" or \"channels_last\"\n",
        "    data_format=None,\n",
        "    # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "#    validation_split=0 i will use test data as val_data....\n",
        "                        )\n",
        "\n",
        "# Compute quantities required for feature-wise normalization\n",
        "# (std, mean, and principal components if ZCA whitening is applied).\n",
        "datagen.fit(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bf5mcmZBtuA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from os.path import join ,exists\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import  Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dropout\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras.regularizers import l2\n",
        "from keras.initializers import glorot_normal\n",
        "from keras.regularizers import l2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeNwQqUIt1BO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def skeleton_dropout(input_shape,num_classes,n_c_factor_3,n_c_1,layers_in_block,dropout):\n",
        "\n",
        "  model=Sequential()\n",
        "  for i in range(layers_in_block):\n",
        "    if i==0:\n",
        "      model.add(Conv2D(((i+1)*n_c_factor_3),kernel_size=3,input_shape=(28,28,1),activation='relu',use_bias=False,kernel_initializer=glorot_normal(seed=None)))#26\n",
        "      model.add(BatchNormalization())\n",
        "    else:\n",
        "      model.add(Conv2D(((i+1)*n_c_factor_3),kernel_size=3,activation='relu',use_bias=False,kernel_initializer=glorot_normal(seed=None)))#24,22\n",
        "      model.add(BatchNormalization())\n",
        "    \n",
        "  model.add(Dropout(dropout))\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))#11\n",
        "  model.add(Conv2D(filters=n_c_1,kernel_size=1,activation='relu',use_bias=False,kernel_initializer=glorot_normal(seed=None)))#11\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  for i in range(layers_in_block):\n",
        "    model.add(Conv2D(((i+1)*n_c_factor_3),kernel_size=3,activation='relu',use_bias=False,kernel_initializer=glorot_normal(seed=None)))#9,7,5\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Dropout(dropout))\n",
        "\n",
        "  #no maxpooling\n",
        "  model.add(Conv2D(filters=num_classes,kernel_size=1,activation='relu',use_bias=False,kernel_initializer=glorot_normal(seed=None)))#5\n",
        "  #activation is avoided.\n",
        "  model.add(Conv2D(filters=num_classes,kernel_size=3,activation='relu',use_bias=False,kernel_initializer=glorot_normal(seed=None))) #3   #provide activation\n",
        "  model.add(Conv2D(filters=num_classes,kernel_size=3,use_bias=False,kernel_initializer=glorot_normal(seed=None)))\n",
        "  ##\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8BDsFlFt2d5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import SGD,Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.001 * 1/(1 + 0.319 * epoch), 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GorEHLwt5sN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f029b5f1-1baa-41ab-ef3c-f764cbb7ba35"
      },
      "source": [
        "#####################introducing learning rate scheduler......#########################################\n",
        "!mkdir drive/'My Drive'/models/mnist-LRS\n",
        "layer_configs=[[7,10],[8,10]]\n",
        "base_path=\"/content/drive/My Drive/models/mnist-LRS/\"\n",
        "dropout=0.1\n",
        "#opt=SGD(lr=0.001,momentum=0.99) ###decay and lr tuning can be done\n",
        "opt=Adam(lr=0.001)\n",
        "for layer_config in layer_configs:\n",
        "\n",
        "  add_path=\"{}_{}_{}/\".format(layer_config[0],layer_config[1],dropout)\n",
        "  if not exists(join(base_path,add_path)):\n",
        "    print(not exists(join(base_path,add_path)))\n",
        "    os.mkdir(join(base_path,add_path))\n",
        "  #print(filepath_initial)\n",
        "  filepath_initial=join(base_path,add_path)\n",
        "  filepath=filepath_initial+\"weights-improvement-{epoch:02d}-{val_acc:.4f}.hdf5\"\n",
        "  cp=ModelCheckpoint(filepath=filepath, monitor='val_acc', verbose=0,save_best_only=True,save_weights_only=False,mode='max',period=1)\n",
        "\n",
        "  input_shape=(28,28,1)\n",
        "  num_classes=10\n",
        "  n_c_factor_3=layer_config[0]\n",
        "  n_c_1=layer_config[1]\n",
        "  layers_in_block=3\n",
        "\n",
        "\n",
        "  model=skeleton_dropout(input_shape,num_classes,n_c_factor_3,n_c_1,layers_in_block,dropout)\n",
        "  model.summary()\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=opt,\n",
        "                metrics=['accuracy'])\n",
        "  \n",
        "\n",
        "  history=model.fit_generator(datagen.flow(X_train, Y_train,batch_size=32),\n",
        "                                validation_data=(X_test, Y_test),\n",
        "                                callbacks=[cp,LearningRateScheduler(scheduler, verbose=1)],\n",
        "                                epochs=20)\n",
        "\n",
        "\n",
        "  acc=history.history['acc']\n",
        "  val_acc=history.history['val_acc']\n",
        "  loss=history.history['loss']\n",
        "  val_loss=history.history['val_loss']\n",
        "\n",
        "  epochs=range(1,len(acc)+1)\n",
        "\n",
        "  plt.plot(epochs,acc,'b',label='Train_acc')\n",
        "  plt.plot(epochs,val_acc,'g',label='Val_acc')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Accuracy')\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘drive/My Drive/models/mnist-LRS’: File exists\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_11 (Conv2D)           (None, 26, 26, 7)         63        \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 26, 26, 7)         28        \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 24, 24, 14)        882       \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 24, 24, 14)        56        \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 22, 22, 21)        2646      \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 22, 22, 21)        84        \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 22, 22, 21)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 11, 11, 21)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 11, 11, 10)        210       \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 11, 11, 10)        40        \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 9, 9, 7)           630       \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 9, 9, 7)           28        \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 7, 7, 14)          882       \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 7, 7, 14)          56        \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 5, 5, 21)          2646      \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 5, 5, 21)          84        \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 5, 5, 21)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 5, 5, 10)          210       \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 3, 3, 10)          900       \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 1, 1, 10)          900       \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 10,345\n",
            "Trainable params: 10,157\n",
            "Non-trainable params: 188\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
            "1875/1875 [==============================] - 48s 26ms/step - loss: 0.3492 - acc: 0.8878 - val_loss: 0.0649 - val_acc: 0.9808\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0007581501.\n",
            "1875/1875 [==============================] - 46s 25ms/step - loss: 0.1136 - acc: 0.9644 - val_loss: 0.0475 - val_acc: 0.9856\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0006105006.\n",
            "1875/1875 [==============================] - 46s 24ms/step - loss: 0.0865 - acc: 0.9736 - val_loss: 0.0411 - val_acc: 0.9875\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0005109862.\n",
            "1875/1875 [==============================] - 46s 24ms/step - loss: 0.0768 - acc: 0.9762 - val_loss: 0.0361 - val_acc: 0.9895\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0004393673.\n",
            "1875/1875 [==============================] - 46s 24ms/step - loss: 0.0677 - acc: 0.9793 - val_loss: 0.0294 - val_acc: 0.9905\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0003853565.\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.0607 - acc: 0.9811 - val_loss: 0.0339 - val_acc: 0.9893\n",
            "Epoch 7/20\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0003431709.\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.0573 - acc: 0.9823 - val_loss: 0.0366 - val_acc: 0.9889\n",
            "Epoch 8/20\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0003093102.\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.0541 - acc: 0.9829 - val_loss: 0.0267 - val_acc: 0.9916\n",
            "Epoch 9/20\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0002815315.\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.0515 - acc: 0.9839 - val_loss: 0.0413 - val_acc: 0.9878\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0002583312.\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.0483 - acc: 0.9853 - val_loss: 0.0263 - val_acc: 0.9917\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0002386635.\n",
            "1875/1875 [==============================] - 46s 24ms/step - loss: 0.0479 - acc: 0.9854 - val_loss: 0.0325 - val_acc: 0.9903\n",
            "Epoch 12/20\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.0002217787.\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.0451 - acc: 0.9860 - val_loss: 0.0272 - val_acc: 0.9919\n",
            "Epoch 13/20\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0002071251.\n",
            "1875/1875 [==============================] - 46s 24ms/step - loss: 0.0453 - acc: 0.9858 - val_loss: 0.0258 - val_acc: 0.9915\n",
            "Epoch 14/20\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0001942879.\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.0411 - acc: 0.9867 - val_loss: 0.0242 - val_acc: 0.9924\n",
            "Epoch 15/20\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0001829491.\n",
            "1875/1875 [==============================] - 46s 24ms/step - loss: 0.0425 - acc: 0.9867 - val_loss: 0.0253 - val_acc: 0.9916\n",
            "Epoch 16/20\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0001728608.\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.0422 - acc: 0.9869 - val_loss: 0.0281 - val_acc: 0.9917\n",
            "Epoch 17/20\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000163827.\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.0414 - acc: 0.9871 - val_loss: 0.0257 - val_acc: 0.9916\n",
            "Epoch 18/20\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0001556905.\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.0407 - acc: 0.9875 - val_loss: 0.0223 - val_acc: 0.9928\n",
            "Epoch 19/20\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0001483239.\n",
            "1875/1875 [==============================] - 46s 24ms/step - loss: 0.0399 - acc: 0.9878 - val_loss: 0.0300 - val_acc: 0.9916\n",
            "Epoch 20/20\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000141623.\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.0374 - acc: 0.9883 - val_loss: 0.0264 - val_acc: 0.9923\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_21 (Conv2D)           (None, 26, 26, 8)         72        \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 26, 26, 8)         32        \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 24, 24, 16)        1152      \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 22, 22, 24)        3456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 22, 22, 24)        96        \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 22, 22, 24)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 11, 11, 24)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 11, 11, 10)        240       \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 11, 11, 10)        40        \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 9, 9, 8)           720       \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 9, 9, 8)           32        \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 7, 7, 16)          1152      \n",
            "_________________________________________________________________\n",
            "batch_normalization_20 (Batc (None, 7, 7, 16)          64        \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 5, 5, 24)          3456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_21 (Batc (None, 5, 5, 24)          96        \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 5, 5, 24)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 5, 5, 10)          240       \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 3, 3, 10)          900       \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 1, 1, 10)          900       \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 12,712\n",
            "Trainable params: 12,500\n",
            "Non-trainable params: 212\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
            "1875/1875 [==============================] - 48s 26ms/step - loss: 0.2249 - acc: 0.9291 - val_loss: 0.0519 - val_acc: 0.9829\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0007581501.\n",
            "1875/1875 [==============================] - 46s 25ms/step - loss: 0.0953 - acc: 0.9707 - val_loss: 0.0392 - val_acc: 0.9891\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0006105006.\n",
            "1875/1875 [==============================] - 46s 24ms/step - loss: 0.0775 - acc: 0.9764 - val_loss: 0.0327 - val_acc: 0.9902\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0005109862.\n",
            "1875/1875 [==============================] - 46s 25ms/step - loss: 0.0669 - acc: 0.9798 - val_loss: 0.0292 - val_acc: 0.9904\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0004393673.\n",
            "1875/1875 [==============================] - 46s 24ms/step - loss: 0.0614 - acc: 0.9809 - val_loss: 0.0322 - val_acc: 0.9903\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0003853565.\n",
            "1875/1875 [==============================] - 46s 24ms/step - loss: 0.0577 - acc: 0.9822 - val_loss: 0.0273 - val_acc: 0.9914\n",
            "Epoch 7/20\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0003431709.\n",
            "1875/1875 [==============================] - 46s 24ms/step - loss: 0.0532 - acc: 0.9835 - val_loss: 0.0252 - val_acc: 0.9918\n",
            "Epoch 8/20\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0003093102.\n",
            "1875/1875 [==============================] - 46s 24ms/step - loss: 0.0484 - acc: 0.9851 - val_loss: 0.0291 - val_acc: 0.9921\n",
            "Epoch 9/20\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0002815315.\n",
            "1875/1875 [==============================] - 46s 24ms/step - loss: 0.0467 - acc: 0.9861 - val_loss: 0.0234 - val_acc: 0.9927\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0002583312.\n",
            "1875/1875 [==============================] - 46s 25ms/step - loss: 0.0484 - acc: 0.9848 - val_loss: 0.0230 - val_acc: 0.9926\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0002386635.\n",
            "1875/1875 [==============================] - 46s 25ms/step - loss: 0.0434 - acc: 0.9864 - val_loss: 0.0222 - val_acc: 0.9929\n",
            "Epoch 12/20\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.0002217787.\n",
            "1875/1875 [==============================] - 46s 25ms/step - loss: 0.0420 - acc: 0.9870 - val_loss: 0.0227 - val_acc: 0.9918\n",
            "Epoch 13/20\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0002071251.\n",
            "1875/1875 [==============================] - 47s 25ms/step - loss: 0.0418 - acc: 0.9871 - val_loss: 0.0210 - val_acc: 0.9929\n",
            "Epoch 14/20\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0001942879.\n",
            "1875/1875 [==============================] - 47s 25ms/step - loss: 0.0402 - acc: 0.9872 - val_loss: 0.0190 - val_acc: 0.9945\n",
            "Epoch 15/20\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0001829491.\n",
            "1875/1875 [==============================] - 47s 25ms/step - loss: 0.0382 - acc: 0.9879 - val_loss: 0.0204 - val_acc: 0.9927\n",
            "Epoch 16/20\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0001728608.\n",
            "1875/1875 [==============================] - 47s 25ms/step - loss: 0.0382 - acc: 0.9879 - val_loss: 0.0198 - val_acc: 0.9930\n",
            "Epoch 17/20\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000163827.\n",
            "1875/1875 [==============================] - 47s 25ms/step - loss: 0.0372 - acc: 0.9884 - val_loss: 0.0194 - val_acc: 0.9935\n",
            "Epoch 18/20\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0001556905.\n",
            "1875/1875 [==============================] - 47s 25ms/step - loss: 0.0367 - acc: 0.9881 - val_loss: 0.0187 - val_acc: 0.9939\n",
            "Epoch 19/20\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0001483239.\n",
            "1875/1875 [==============================] - 47s 25ms/step - loss: 0.0353 - acc: 0.9891 - val_loss: 0.0190 - val_acc: 0.9942\n",
            "Epoch 20/20\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000141623.\n",
            "1875/1875 [==============================] - 47s 25ms/step - loss: 0.0343 - acc: 0.9890 - val_loss: 0.0191 - val_acc: 0.9937\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npAQhIiIp/X+rhcE3krtLiAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwlcS-PUa9mE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}