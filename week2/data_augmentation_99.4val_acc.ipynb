{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist-Adamwithallimprovements.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohanaditya910/eip-season4-batch1/blob/master/week2/data_augmentation_99.4val_acc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofdloK0vtKYQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "9c3f65b8-4ec9-4a3e-99ec-ce709a17565c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uC_NakgYtZMF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb30118a-13de-4f66-c9e7-e6d705e6c209"
      },
      "source": [
        "!mkdir drive/'My Drive'/models/mnist-data_augmentation"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘drive/My Drive/models/mnist-data_augmentation’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JL1kZKW0tchC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "8957956d-5dec-4f62-fceb-6c8434385cc4"
      },
      "source": [
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SE2YC6V4toP3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyJGlW4YtqJr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#########data augmentation cell#####################\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "    samplewise_center=False,  # set each sample mean to 0\n",
        "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "    samplewise_std_normalization=False,  # divide each input by its std\n",
        "    zca_whitening=False,  # apply ZCA whitening\n",
        "    zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "    rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    # randomly shift images horizontally (fraction of total width)\n",
        "    width_shift_range=0.05,\n",
        "    # randomly shift images vertically (fraction of total height)\n",
        "    height_shift_range=0.05,\n",
        "    shear_range=0.2,  # set range for random shear\n",
        "    zoom_range=0.05,  # set range for random zoom\n",
        "    channel_shift_range=0.,  # set range for random channel shifts\n",
        "    # set mode for filling points outside the input boundaries\n",
        "    fill_mode='nearest',\n",
        "    cval=0.,  # value used for fill_mode = \"constant\"\n",
        "    horizontal_flip=False,  # randomly flip images   ############not advisable because some numbers when flipped can represent other numbers..\n",
        "    vertical_flip=False,  # randomly flip images     #########################\n",
        "    # set rescaling factor (applied before any other transformation)\n",
        "    rescale=None, #already done....\n",
        "    # set function that will be applied on each input\n",
        "    preprocessing_function=None,\n",
        "\n",
        "##############can explore this part......\n",
        "\n",
        "\n",
        "    # image data format, either \"channels_first\" or \"channels_last\"\n",
        "    data_format=None,\n",
        "    # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "#    validation_split=0 i will use test data as val_data....\n",
        "                        )\n",
        "\n",
        "# Compute quantities required for feature-wise normalization\n",
        "# (std, mean, and principal components if ZCA whitening is applied).\n",
        "datagen.fit(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bf5mcmZBtuA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from os.path import join ,exists\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import  Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dropout\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras.regularizers import l2\n",
        "from keras.initializers import glorot_normal\n",
        "from keras.regularizers import l2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeNwQqUIt1BO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def skeleton_dropout(input_shape,num_classes,n_c_factor_3,n_c_1,layers_in_block,dropout):\n",
        "\n",
        "  model=Sequential()\n",
        "  for i in range(layers_in_block):\n",
        "    if i==0:\n",
        "      model.add(Conv2D(((i+1)*n_c_factor_3),kernel_size=3,input_shape=(28,28,1),activation='relu',use_bias=False,kernel_initializer=glorot_normal(seed=None)))#26\n",
        "      model.add(BatchNormalization())\n",
        "    else:\n",
        "      model.add(Conv2D(((i+1)*n_c_factor_3),kernel_size=3,activation='relu',use_bias=False,kernel_initializer=glorot_normal(seed=None)))#24,22\n",
        "      model.add(BatchNormalization())\n",
        "    \n",
        "  model.add(Dropout(dropout))\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))#11\n",
        "  model.add(Conv2D(filters=n_c_1,kernel_size=1,activation='relu',use_bias=False,kernel_initializer=glorot_normal(seed=None)))#11\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  for i in range(layers_in_block):\n",
        "    model.add(Conv2D(((i+1)*n_c_factor_3),kernel_size=3,activation='relu',use_bias=False,kernel_initializer=glorot_normal(seed=None)))#9,7,5\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Dropout(dropout))\n",
        "\n",
        "  #no maxpooling\n",
        "  model.add(Conv2D(filters=num_classes,kernel_size=1,activation='relu',use_bias=False,kernel_initializer=glorot_normal(seed=None)))#5\n",
        "  #activation is avoided.\n",
        "  model.add(Conv2D(filters=num_classes,kernel_size=3,activation='relu',use_bias=False,kernel_initializer=glorot_normal(seed=None))) #3   #provide activation\n",
        "  model.add(Conv2D(filters=num_classes,kernel_size=3,use_bias=False,kernel_initializer=glorot_normal(seed=None)))\n",
        "  ##\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8BDsFlFt2d5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import SGD,Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.001 * 1/(1 + 0.319 * epoch), 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GorEHLwt5sN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f029b5f1-1baa-41ab-ef3c-f764cbb7ba35"
      },
      "source": [
        "#####################introducing learning rate scheduler......#########################################\n",
        "!mkdir drive/'My Drive'/models/mnist-LRS\n",
        "layer_configs=[[7,10],[8,10]]\n",
        "base_path=\"/content/drive/My Drive/models/mnist-LRS/\"\n",
        "dropout=0.1\n",
        "#opt=SGD(lr=0.001,momentum=0.99) ###decay and lr tuning can be done\n",
        "opt=Adam(lr=0.001)\n",
        "for layer_config in layer_configs:\n",
        "\n",
        "  add_path=\"{}_{}_{}/\".format(layer_config[0],layer_config[1],dropout)\n",
        "  if not exists(join(base_path,add_path)):\n",
        "    print(not exists(join(base_path,add_path)))\n",
        "    os.mkdir(join(base_path,add_path))\n",
        "  #print(filepath_initial)\n",
        "  filepath_initial=join(base_path,add_path)\n",
        "  filepath=filepath_initial+\"weights-improvement-{epoch:02d}-{val_acc:.4f}.hdf5\"\n",
        "  cp=ModelCheckpoint(filepath=filepath, monitor='val_acc', verbose=0,save_best_only=True,save_weights_only=False,mode='max',period=1)\n",
        "\n",
        "  input_shape=(28,28,1)\n",
        "  num_classes=10\n",
        "  n_c_factor_3=layer_config[0]\n",
        "  n_c_1=layer_config[1]\n",
        "  layers_in_block=3\n",
        "\n",
        "\n",
        "  model=skeleton_dropout(input_shape,num_classes,n_c_factor_3,n_c_1,layers_in_block,dropout)\n",
        "  model.summary()\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=opt,\n",
        "                metrics=['accuracy'])\n",
        "  \n",
        "\n",
        "  history=model.fit_generator(datagen.flow(X_train, Y_train,batch_size=32),\n",
        "                                validation_data=(X_test, Y_test),\n",
        "                                callbacks=[cp,LearningRateScheduler(scheduler, verbose=1)],\n",
        "                                epochs=20)\n",
        "\n",
        "\n",
        "  acc=history.history['acc']\n",
        "  val_acc=history.history['val_acc']\n",
        "  loss=history.history['loss']\n",
        "  val_loss=history.history['val_loss']\n",
        "\n",
        "  epochs=range(1,len(acc)+1)\n",
        "\n",
        "  plt.plot(epochs,acc,'b',label='Train_acc')\n",
        "  plt.plot(epochs,val_acc,'g',label='Val_acc')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Accuracy')\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘drive/My Drive/models/mnist-LRS’: File exists\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_11 (Conv2D)           (None, 26, 26, 7)         63        \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 26, 26, 7)         28        \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 24, 24, 14)        882       \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 24, 24, 14)        56        \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 22, 22, 21)        2646      \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 22, 22, 21)        84        \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 22, 22, 21)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 11, 11, 21)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 11, 11, 10)        210       \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 11, 11, 10)        40        \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 9, 9, 7)           630       \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 9, 9, 7)           28        \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 7, 7, 14)          882       \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 7, 7, 14)          56        \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 5, 5, 21)          2646      \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 5, 5, 21)          84        \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 5, 5, 21)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 5, 5, 10)          210       \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 3, 3, 10)          900       \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 1, 1, 10)          900       \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 10,345\n",
            "Trainable params: 10,157\n",
            "Non-trainable params: 188\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
            "1875/1875 [==============================] - 48s 26ms/step - loss: 0.3492 - acc: 0.8878 - val_loss: 0.0649 - val_acc: 0.9808\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0007581501.\n",
            "1875/1875 [==============================] - 46s 25ms/step - loss: 0.1136 - acc: 0.9644 - val_loss: 0.0475 - val_acc: 0.9856\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0006105006.\n",
            "1875/1875 [==============================] - 46s 24ms/step - loss: 0.0865 - acc: 0.9736 - val_loss: 0.0411 - val_acc: 0.9875\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0005109862.\n",
            "1875/1875 [==============================] - 46s 24ms/step - loss: 0.0768 - acc: 0.9762 - val_loss: 0.0361 - val_acc: 0.9895\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0004393673.\n",
            "1875/1875 [==============================] - 46s 24ms/step - loss: 0.0677 - acc: 0.9793 - val_loss: 0.0294 - val_acc: 0.9905\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0003853565.\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.0607 - acc: 0.9811 - val_loss: 0.0339 - val_acc: 0.9893\n",
            "Epoch 7/20\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0003431709.\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.0573 - acc: 0.9823 - val_loss: 0.0366 - val_acc: 0.9889\n",
            "Epoch 8/20\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0003093102.\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.0541 - acc: 0.9829 - val_loss: 0.0267 - val_acc: 0.9916\n",
            "Epoch 9/20\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0002815315.\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.0515 - acc: 0.9839 - val_loss: 0.0413 - val_acc: 0.9878\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0002583312.\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.0483 - acc: 0.9853 - val_loss: 0.0263 - val_acc: 0.9917\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0002386635.\n",
            "1875/1875 [==============================] - 46s 24ms/step - loss: 0.0479 - acc: 0.9854 - val_loss: 0.0325 - val_acc: 0.9903\n",
            "Epoch 12/20\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.0002217787.\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.0451 - acc: 0.9860 - val_loss: 0.0272 - val_acc: 0.9919\n",
            "Epoch 13/20\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0002071251.\n",
            "1875/1875 [==============================] - 46s 24ms/step - loss: 0.0453 - acc: 0.9858 - val_loss: 0.0258 - val_acc: 0.9915\n",
            "Epoch 14/20\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0001942879.\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.0411 - acc: 0.9867 - val_loss: 0.0242 - val_acc: 0.9924\n",
            "Epoch 15/20\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0001829491.\n",
            "1875/1875 [==============================] - 46s 24ms/step - loss: 0.0425 - acc: 0.9867 - val_loss: 0.0253 - val_acc: 0.9916\n",
            "Epoch 16/20\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0001728608.\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.0422 - acc: 0.9869 - val_loss: 0.0281 - val_acc: 0.9917\n",
            "Epoch 17/20\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000163827.\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.0414 - acc: 0.9871 - val_loss: 0.0257 - val_acc: 0.9916\n",
            "Epoch 18/20\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0001556905.\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.0407 - acc: 0.9875 - val_loss: 0.0223 - val_acc: 0.9928\n",
            "Epoch 19/20\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0001483239.\n",
            "1875/1875 [==============================] - 46s 24ms/step - loss: 0.0399 - acc: 0.9878 - val_loss: 0.0300 - val_acc: 0.9916\n",
            "Epoch 20/20\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000141623.\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.0374 - acc: 0.9883 - val_loss: 0.0264 - val_acc: 0.9923\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_21 (Conv2D)           (None, 26, 26, 8)         72        \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 26, 26, 8)         32        \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 24, 24, 16)        1152      \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 22, 22, 24)        3456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 22, 22, 24)        96        \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 22, 22, 24)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 11, 11, 24)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 11, 11, 10)        240       \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 11, 11, 10)        40        \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 9, 9, 8)           720       \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 9, 9, 8)           32        \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 7, 7, 16)          1152      \n",
            "_________________________________________________________________\n",
            "batch_normalization_20 (Batc (None, 7, 7, 16)          64        \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 5, 5, 24)          3456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_21 (Batc (None, 5, 5, 24)          96        \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 5, 5, 24)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 5, 5, 10)          240       \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 3, 3, 10)          900       \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 1, 1, 10)          900       \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 12,712\n",
            "Trainable params: 12,500\n",
            "Non-trainable params: 212\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
            "1875/1875 [==============================] - 48s 26ms/step - loss: 0.2249 - acc: 0.9291 - val_loss: 0.0519 - val_acc: 0.9829\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0007581501.\n",
            "1875/1875 [==============================] - 46s 25ms/step - loss: 0.0953 - acc: 0.9707 - val_loss: 0.0392 - val_acc: 0.9891\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0006105006.\n",
            "1875/1875 [==============================] - 46s 24ms/step - loss: 0.0775 - acc: 0.9764 - val_loss: 0.0327 - val_acc: 0.9902\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0005109862.\n",
            "1875/1875 [==============================] - 46s 25ms/step - loss: 0.0669 - acc: 0.9798 - val_loss: 0.0292 - val_acc: 0.9904\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0004393673.\n",
            "1875/1875 [==============================] - 46s 24ms/step - loss: 0.0614 - acc: 0.9809 - val_loss: 0.0322 - val_acc: 0.9903\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0003853565.\n",
            "1875/1875 [==============================] - 46s 24ms/step - loss: 0.0577 - acc: 0.9822 - val_loss: 0.0273 - val_acc: 0.9914\n",
            "Epoch 7/20\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0003431709.\n",
            "1875/1875 [==============================] - 46s 24ms/step - loss: 0.0532 - acc: 0.9835 - val_loss: 0.0252 - val_acc: 0.9918\n",
            "Epoch 8/20\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0003093102.\n",
            "1875/1875 [==============================] - 46s 24ms/step - loss: 0.0484 - acc: 0.9851 - val_loss: 0.0291 - val_acc: 0.9921\n",
            "Epoch 9/20\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0002815315.\n",
            "1875/1875 [==============================] - 46s 24ms/step - loss: 0.0467 - acc: 0.9861 - val_loss: 0.0234 - val_acc: 0.9927\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0002583312.\n",
            "1875/1875 [==============================] - 46s 25ms/step - loss: 0.0484 - acc: 0.9848 - val_loss: 0.0230 - val_acc: 0.9926\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0002386635.\n",
            "1875/1875 [==============================] - 46s 25ms/step - loss: 0.0434 - acc: 0.9864 - val_loss: 0.0222 - val_acc: 0.9929\n",
            "Epoch 12/20\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.0002217787.\n",
            "1875/1875 [==============================] - 46s 25ms/step - loss: 0.0420 - acc: 0.9870 - val_loss: 0.0227 - val_acc: 0.9918\n",
            "Epoch 13/20\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0002071251.\n",
            "1875/1875 [==============================] - 47s 25ms/step - loss: 0.0418 - acc: 0.9871 - val_loss: 0.0210 - val_acc: 0.9929\n",
            "Epoch 14/20\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0001942879.\n",
            "1875/1875 [==============================] - 47s 25ms/step - loss: 0.0402 - acc: 0.9872 - val_loss: 0.0190 - val_acc: 0.9945\n",
            "Epoch 15/20\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0001829491.\n",
            "1875/1875 [==============================] - 47s 25ms/step - loss: 0.0382 - acc: 0.9879 - val_loss: 0.0204 - val_acc: 0.9927\n",
            "Epoch 16/20\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0001728608.\n",
            "1875/1875 [==============================] - 47s 25ms/step - loss: 0.0382 - acc: 0.9879 - val_loss: 0.0198 - val_acc: 0.9930\n",
            "Epoch 17/20\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000163827.\n",
            "1875/1875 [==============================] - 47s 25ms/step - loss: 0.0372 - acc: 0.9884 - val_loss: 0.0194 - val_acc: 0.9935\n",
            "Epoch 18/20\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0001556905.\n",
            "1875/1875 [==============================] - 47s 25ms/step - loss: 0.0367 - acc: 0.9881 - val_loss: 0.0187 - val_acc: 0.9939\n",
            "Epoch 19/20\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0001483239.\n",
            "1875/1875 [==============================] - 47s 25ms/step - loss: 0.0353 - acc: 0.9891 - val_loss: 0.0190 - val_acc: 0.9942\n",
            "Epoch 20/20\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000141623.\n",
            "1875/1875 [==============================] - 47s 25ms/step - loss: 0.0343 - acc: 0.9890 - val_loss: 0.0191 - val_acc: 0.9937\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npAQhIiIp/X+rhcE3krtLiAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmFlIuHJt7GL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsSuIT9nt699",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b958339c-780d-40eb-da81-b760018f135f"
      },
      "source": [
        "input_shape=(28,28,1)\n",
        "num_classes=10\n",
        "n_c_factor_3=5\n",
        "n_c_1=10\n",
        "layers_in_block=3\n",
        "dropout=0.1\n",
        "\n",
        "\n",
        "model=skeleton_dropout(input_shape,num_classes,n_c_factor_3,n_c_1,layers_in_block,dropout)\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "history=model.fit_generator(datagen.flow(X_train, Y_train,batch_size=32),\n",
        "                              validation_data=(X_test, Y_test),\n",
        "                              callbacks=[LearningRateScheduler(scheduler, verbose=1)],\n",
        "                              epochs=20)\n",
        "\n",
        "\n",
        "acc=history.history['acc']\n",
        "val_acc=history.history['val_acc']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs=range(1,len(acc)+1)\n",
        "\n",
        "plt.plot(epochs,acc,'b',label='Train_acc')\n",
        "plt.plot(epochs,val_acc,'g',label='Val_acc')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_31 (Conv2D)           (None, 26, 26, 5)         45        \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 26, 26, 5)         20        \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 24, 24, 10)        450       \n",
            "_________________________________________________________________\n",
            "batch_normalization_23 (Batc (None, 24, 24, 10)        40        \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 22, 22, 15)        1350      \n",
            "_________________________________________________________________\n",
            "batch_normalization_24 (Batc (None, 22, 22, 15)        60        \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 22, 22, 15)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 11, 11, 15)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 11, 11, 10)        150       \n",
            "_________________________________________________________________\n",
            "batch_normalization_25 (Batc (None, 11, 11, 10)        40        \n",
            "_________________________________________________________________\n",
            "conv2d_35 (Conv2D)           (None, 9, 9, 5)           450       \n",
            "_________________________________________________________________\n",
            "batch_normalization_26 (Batc (None, 9, 9, 5)           20        \n",
            "_________________________________________________________________\n",
            "conv2d_36 (Conv2D)           (None, 7, 7, 10)          450       \n",
            "_________________________________________________________________\n",
            "batch_normalization_27 (Batc (None, 7, 7, 10)          40        \n",
            "_________________________________________________________________\n",
            "conv2d_37 (Conv2D)           (None, 5, 5, 15)          1350      \n",
            "_________________________________________________________________\n",
            "batch_normalization_28 (Batc (None, 5, 5, 15)          60        \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 5, 5, 15)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_38 (Conv2D)           (None, 5, 5, 10)          150       \n",
            "_________________________________________________________________\n",
            "conv2d_39 (Conv2D)           (None, 3, 3, 10)          900       \n",
            "_________________________________________________________________\n",
            "conv2d_40 (Conv2D)           (None, 1, 1, 10)          900       \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 6,475\n",
            "Trainable params: 6,335\n",
            "Non-trainable params: 140\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
            "1875/1875 [==============================] - 50s 27ms/step - loss: 0.2655 - acc: 0.9158 - val_loss: 0.0776 - val_acc: 0.9758\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0007581501.\n",
            "1875/1875 [==============================] - 47s 25ms/step - loss: 0.1225 - acc: 0.9621 - val_loss: 0.0548 - val_acc: 0.9827\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0006105006.\n",
            "1875/1875 [==============================] - 47s 25ms/step - loss: 0.1010 - acc: 0.9695 - val_loss: 0.0455 - val_acc: 0.9861\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0005109862.\n",
            "1875/1875 [==============================] - 47s 25ms/step - loss: 0.0876 - acc: 0.9731 - val_loss: 0.0380 - val_acc: 0.9885\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0004393673.\n",
            "1875/1875 [==============================] - 47s 25ms/step - loss: 0.0802 - acc: 0.9746 - val_loss: 0.0375 - val_acc: 0.9885\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0003853565.\n",
            "1875/1875 [==============================] - 47s 25ms/step - loss: 0.0754 - acc: 0.9769 - val_loss: 0.0322 - val_acc: 0.9895\n",
            "Epoch 7/20\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0003431709.\n",
            "1875/1875 [==============================] - 47s 25ms/step - loss: 0.0723 - acc: 0.9778 - val_loss: 0.0389 - val_acc: 0.9876\n",
            "Epoch 8/20\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0003093102.\n",
            "1875/1875 [==============================] - 47s 25ms/step - loss: 0.0671 - acc: 0.9794 - val_loss: 0.0322 - val_acc: 0.9894\n",
            "Epoch 9/20\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0002815315.\n",
            "1875/1875 [==============================] - 47s 25ms/step - loss: 0.0661 - acc: 0.9796 - val_loss: 0.0301 - val_acc: 0.9907\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0002583312.\n",
            "1875/1875 [==============================] - 47s 25ms/step - loss: 0.0643 - acc: 0.9799 - val_loss: 0.0276 - val_acc: 0.9905\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0002386635.\n",
            "1875/1875 [==============================] - 47s 25ms/step - loss: 0.0615 - acc: 0.9806 - val_loss: 0.0283 - val_acc: 0.9909\n",
            "Epoch 12/20\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.0002217787.\n",
            "1875/1875 [==============================] - 47s 25ms/step - loss: 0.0614 - acc: 0.9816 - val_loss: 0.0314 - val_acc: 0.9894\n",
            "Epoch 13/20\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0002071251.\n",
            "1875/1875 [==============================] - 48s 25ms/step - loss: 0.0602 - acc: 0.9814 - val_loss: 0.0275 - val_acc: 0.9912\n",
            "Epoch 14/20\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0001942879.\n",
            "1875/1875 [==============================] - 47s 25ms/step - loss: 0.0573 - acc: 0.9823 - val_loss: 0.0268 - val_acc: 0.9912\n",
            "Epoch 15/20\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0001829491.\n",
            "1875/1875 [==============================] - 47s 25ms/step - loss: 0.0575 - acc: 0.9825 - val_loss: 0.0289 - val_acc: 0.9909\n",
            "Epoch 16/20\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0001728608.\n",
            "1875/1875 [==============================] - 46s 25ms/step - loss: 0.0554 - acc: 0.9830 - val_loss: 0.0315 - val_acc: 0.9906\n",
            "Epoch 17/20\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000163827.\n",
            "1875/1875 [==============================] - 47s 25ms/step - loss: 0.0543 - acc: 0.9829 - val_loss: 0.0302 - val_acc: 0.9912\n",
            "Epoch 18/20\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0001556905.\n",
            "1875/1875 [==============================] - 47s 25ms/step - loss: 0.0545 - acc: 0.9834 - val_loss: 0.0269 - val_acc: 0.9907\n",
            "Epoch 19/20\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0001483239.\n",
            "1875/1875 [==============================] - 47s 25ms/step - loss: 0.0527 - acc: 0.9833 - val_loss: 0.0258 - val_acc: 0.9917\n",
            "Epoch 20/20\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000141623.\n",
            "1875/1875 [==============================] - 48s 25ms/step - loss: 0.0526 - acc: 0.9842 - val_loss: 0.0261 - val_acc: 0.9913\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3UMTIdnt6zK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBquI9eFt6i_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d6bdfcfd-192c-4fa4-d739-dc34ad4dfeca"
      },
      "source": [
        "opt=Adam(lr=0.002)\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.001 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "input_shape=(28,28,1)\n",
        "num_classes=10\n",
        "n_c_factor_3=5\n",
        "n_c_1=10\n",
        "layers_in_block=3\n",
        "dropout=0.1\n",
        "\n",
        "\n",
        "model=skeleton_dropout(input_shape,num_classes,n_c_factor_3,n_c_1,layers_in_block,dropout)\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "history=model.fit_generator(datagen.flow(X_train, Y_train,batch_size=32),\n",
        "                              validation_data=(X_test, Y_test),\n",
        "                              callbacks=[LearningRateScheduler(scheduler, verbose=1)],\n",
        "                              epochs=20)\n",
        "\n",
        "\n",
        "acc=history.history['acc']\n",
        "val_acc=history.history['val_acc']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs=range(1,len(acc)+1)\n",
        "\n",
        "plt.plot(epochs,acc,'b',label='Train_acc')\n",
        "plt.plot(epochs,val_acc,'g',label='Val_acc')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_41 (Conv2D)           (None, 26, 26, 5)         45        \n",
            "_________________________________________________________________\n",
            "batch_normalization_29 (Batc (None, 26, 26, 5)         20        \n",
            "_________________________________________________________________\n",
            "conv2d_42 (Conv2D)           (None, 24, 24, 10)        450       \n",
            "_________________________________________________________________\n",
            "batch_normalization_30 (Batc (None, 24, 24, 10)        40        \n",
            "_________________________________________________________________\n",
            "conv2d_43 (Conv2D)           (None, 22, 22, 15)        1350      \n",
            "_________________________________________________________________\n",
            "batch_normalization_31 (Batc (None, 22, 22, 15)        60        \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 22, 22, 15)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 11, 11, 15)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_44 (Conv2D)           (None, 11, 11, 10)        150       \n",
            "_________________________________________________________________\n",
            "batch_normalization_32 (Batc (None, 11, 11, 10)        40        \n",
            "_________________________________________________________________\n",
            "conv2d_45 (Conv2D)           (None, 9, 9, 5)           450       \n",
            "_________________________________________________________________\n",
            "batch_normalization_33 (Batc (None, 9, 9, 5)           20        \n",
            "_________________________________________________________________\n",
            "conv2d_46 (Conv2D)           (None, 7, 7, 10)          450       \n",
            "_________________________________________________________________\n",
            "batch_normalization_34 (Batc (None, 7, 7, 10)          40        \n",
            "_________________________________________________________________\n",
            "conv2d_47 (Conv2D)           (None, 5, 5, 15)          1350      \n",
            "_________________________________________________________________\n",
            "batch_normalization_35 (Batc (None, 5, 5, 15)          60        \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 5, 5, 15)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_48 (Conv2D)           (None, 5, 5, 10)          150       \n",
            "_________________________________________________________________\n",
            "conv2d_49 (Conv2D)           (None, 3, 3, 10)          900       \n",
            "_________________________________________________________________\n",
            "conv2d_50 (Conv2D)           (None, 1, 1, 10)          900       \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 6,475\n",
            "Trainable params: 6,335\n",
            "Non-trainable params: 140\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
            "1875/1875 [==============================] - 52s 28ms/step - loss: 0.4081 - acc: 0.8657 - val_loss: 0.0738 - val_acc: 0.9777\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0007581501.\n",
            "1875/1875 [==============================] - 48s 26ms/step - loss: 0.1393 - acc: 0.9562 - val_loss: 0.0595 - val_acc: 0.9810\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0006105006.\n",
            "1875/1875 [==============================] - 48s 26ms/step - loss: 0.1096 - acc: 0.9661 - val_loss: 0.0544 - val_acc: 0.9837\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0005109862.\n",
            "1875/1875 [==============================] - 48s 25ms/step - loss: 0.0981 - acc: 0.9696 - val_loss: 0.0532 - val_acc: 0.9834\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0004393673.\n",
            "  19/1875 [..............................] - ETA: 41s - loss: 0.0815 - acc: 0.9753"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}